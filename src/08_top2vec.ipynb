{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8040a331-4b43-4a74-a6fb-a79c87a943f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from top2vec import Top2Vec\n",
    "from ast import literal_eval\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from utils import topic_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f79b5-d089-4fc8-9608-fc3d1084a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import strip_tags\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc82442-2c00-4529-9732-6f083ac642be",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333578ab-9f86-437a-a56d-75535b5d3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/lemmas.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a976c8-a9e8-4943-8db7-97927c7a70e2",
   "metadata": {},
   "source": [
    "# Select a subsample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abbf204-6248-4cad-a055-3a3f801b611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "# df_sub = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709df5c7-e28b-4ea4-ab1e-91dcf73eeb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3779a7ee-96ea-483e-a68f-50f669748fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101e879c-27eb-4fd4-b111-90af25f0336a",
   "metadata": {},
   "source": [
    "# Filter the data\n",
    "Filter out all POS but Nouns (N), Adjectives (A) and Verbs (V)\n",
    "\n",
    "Filter out frequent (stop)words that does not carry any extra semantic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1eacb-ed3d-4350-af83-f9ff7613d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['mít', 'jít', 'být', 'dát', 'moci']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9682db4-627b-483c-97f7-0d59e5bb561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lemmas_filtered_column = []\n",
    "\n",
    "# extract lemmas with N, A or V POS tag\n",
    "for index, poem in df_sub.iterrows():\n",
    "    if index % 1000 == 0:\n",
    "        print(index, end=' ')\n",
    "    \n",
    "    lemmas_filtered_poem = []\n",
    "    lemmas_poem = literal_eval(poem['lemmas'])\n",
    "    for lemma_pos in lemmas_poem:\n",
    "        lemma, pos = lemma_pos\n",
    "        if pos in ['N', 'A', 'V'] and lemma not in stopwords:\n",
    "            lemmas_filtered_poem.append(lemma)\n",
    "    lemmas_filtered_column.append(lemmas_filtered_poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de9d06-ddae-430f-966e-b4683cf475db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['lemmas_filtered'] = lemmas_filtered_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057d9ca-2f33-4788-a1dc-de69c58d8385",
   "metadata": {},
   "source": [
    "# Create a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662bde3-b0ff-4640-acfa-96c5388f1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_frequency = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34995549-2eb8-4005-a8ce-4e8049b0329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(df_sub['lemmas_filtered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57ea6a-6391-44bb-ac03-685b431ffd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c6c32-4e04-4cde-bc94-b5ac74f422ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out words\n",
    "dictionary.filter_extremes(no_below=min_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3bbfd8-bdb6-495e-8077-39cbb5f5ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a43948-705d-460d-85ff-6f89e2c8b45b",
   "metadata": {},
   "source": [
    "# Join preprocessed tokens into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6dff6a-188a-4a34-bb5a-0b6b12ffe6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv('../data/training_data_top2vec.csv')\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63163f0-9c86-42ee-b970-a0987db28368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['texts'] = df_sub['lemmas_filtered'].apply(lambda x: ' '.join(x[2:-2].split(\"', '\")))\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c05606-6b71-4153-a734-ff13d1074807",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "API: https://top2vec.readthedocs.io/en/latest/api.html\n",
    "\n",
    "Example: https://towardsdatascience.com/how-to-perform-topic-modeling-with-top2vec-1ae9bb4e89dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52021f20-e668-4206-a4c1-3688ef62f413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_models = [\n",
    "    'doc2vec',\n",
    "    'universal-sentence-encoder',\n",
    "    'universal-sentence-encoder-multilingual',\n",
    "    'distiluse-base-multilingual-cased',\n",
    "    'all-MiniLM-L6-v2',\n",
    "    'paraphrase-multilingual-MiniLM-L12-v2'\n",
    "]\n",
    "\n",
    "embedding_models = [\n",
    "    'doc2vec'\n",
    "]\n",
    "\n",
    "umap_args = {'n_neighbors': 15,\n",
    "             'n_components': 5,\n",
    "             'metric': 'cosine'}\n",
    "\n",
    "hdbscan_args = {'min_cluster_size': 15,\n",
    "                'metric': 'euclidean',\n",
    "                'cluster_selection_method': 'leaf'}\n",
    "\n",
    "speed = 'deep-learn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda96705-d226-4eef-9d77-5cd38a6bac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(document):\n",
    "    return simple_preprocess(strip_tags(document), deacc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd6b662-5a3d-4f76-9e2d-df0ab5cff216",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "\n",
    "for embedding_model in embedding_models:\n",
    "    start = time.time()\n",
    "    \n",
    "    # train the model\n",
    "    model = Top2Vec(documents=df_sub['texts'].values,\n",
    "                    speed=speed,\n",
    "                    min_count=min_frequency,\n",
    "                    umap_args=umap_args,\n",
    "                    hdbscan_args=hdbscan_args,\n",
    "                    tokenizer=custom_tokenizer,\n",
    "                    embedding_model=embedding_model)\n",
    "    \n",
    "    # compute coherence of the model\n",
    "    print(model.topic_words)\n",
    "    \n",
    "    # cm = CoherenceModel(topics=model.topic_words, topn=10, dictionary=dictionary, texts=df_sub['lemmas_filtered'], coherence='c_v')\n",
    "    # coherence = cm.get_coherence()\n",
    "       \n",
    "    training_time = (time.time() - start)/60\n",
    "    results.append((embedding_model, coherence, model.get_num_topics(), training_time))\n",
    "    \n",
    "    #print('Embedding model: {}. Coherence: {}. Number of topics: {} (training took {} min).'.format(\n",
    "    #          embedding_model, coherence, model.get_num_topics(), round(training_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6501d9-a32e-4b22-b94e-2545d6efa486",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append((embedding_model, model.get_num_topics(), training_time))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd450fc-a2f9-4e10-885e-b26a0afc9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.topic_words[4])\n",
    "model.save('../results/top2vec/top2vec_doc2vec_clean.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a643ef-588d-45d2-8d61-fdb07101df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.topic_word_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06b61d2-55cd-412d-b287-89b45caefbb0",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa527b3-a73e-4571-a5b1-76174c5b2ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('../results/top2vec/results_top2vec.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a5a0dc-d618-46c3-98ae-7942251b1eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = results.embedding_model.values\n",
    "y1 = results.coherence.values\n",
    "y2 = results.num_topics.values\n",
    "y3 = results.diversity.values\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671c909-6737-40cc-9059-ba643e9c7bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with two subplots\n",
    "# fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "fig, ax1 = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ax1.set_xlabel('Embedding Model')\n",
    "ax1.set_ylabel('Topic Coherence Score')\n",
    "ax1.bar(x, y1)\n",
    "ax1.set_xticklabels(x, rotation=90)\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Add labels to the bars\n",
    "for i in range(len(x)):\n",
    "    ax1.text(i, y1[i], str(round(y1[i], 2)), ha='center', va='bottom')\n",
    "\n",
    "# # ax2 = ax1.twinx()\n",
    "\n",
    "# ax2.set_ylabel('Number of Topics Found')\n",
    "# ax2.set_xlabel('Embedding Model')\n",
    "# ax2.bar(x, y2, color='tab:red')\n",
    "# ax2.set_xticklabels(x, rotation=90)\n",
    "# ax2.tick_params(axis='y')\n",
    "\n",
    "# # Add labels to the bars\n",
    "# for i in range(len(x)):\n",
    "#     ax2.text(i, y2[i], str(y2[i]), ha='center', va='bottom')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('top2vec_coherence.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85955f20-36ff-4140-944b-87883534b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, ax2 = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ax2.set_ylabel('Number of Topics Found')\n",
    "ax2.set_xlabel('Embedding Model')\n",
    "ax2.bar(x, y2, color='tab:red')\n",
    "ax2.set_xticklabels(x, rotation=45, ha='right')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Add labels to the bars\n",
    "for i in range(len(x)):\n",
    "    ax2.text(i, y2[i], str(y2[i]), ha='center', va='bottom')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('top2vec_num_topics.png', dpi=400, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de627696-f01b-48f1-aee6-21d65f00229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, ax2 = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ax2.set_ylabel('Topic Diversity Score')\n",
    "ax2.set_xlabel('Embedding Model')\n",
    "ax2.bar(x, y3, color='tab:green')\n",
    "ax2.set_xticklabels(x, rotation=90)\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Add labels to the bars\n",
    "for i in range(len(x)):\n",
    "    ax2.text(i, y3[i], str(round(y3[i], 2)), ha='center', va='bottom')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('top2vec_diversity.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5678e00-dacf-42de-b987-fa66dcdb6eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = results.embedding_model.values\n",
    "y1 = results.coherence.values\n",
    "y2 = results.num_topics.values\n",
    "y3 = results.diversity.values\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1e114-10c5-4f16-b311-24fe609c7242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# create example data\n",
    "data = {\n",
    "    \"Coherence\": [round(i, 2) for i in y1],\n",
    "    \"Diversity\": [round(i, 2) for i in y3]\n",
    "}\n",
    "index = x\n",
    "result = pd.DataFrame(data, index=results.embedding_model.values)\n",
    "\n",
    "# plot data\n",
    "x = np.arange(len(result.index))  # x locations of bars\n",
    "width = 0.4  # width of bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "rects1 = ax.bar(x - width/2, result[\"Coherence\"], width, label=\"Coherence\")\n",
    "rects2 = ax.bar(x + width/2, result[\"Diversity\"], width, label=\"Diversity\")\n",
    "\n",
    "# add values on top of bars\n",
    "for rect in rects1:\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, height, str(height),\n",
    "            ha='center', va='bottom')\n",
    "for rect in rects2:\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, height, str(height),\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "# add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel(\"Score\")\n",
    "# ax.set_title(\"Major and Minor topics by topic name\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(result.index, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.savefig('top2vec-coherence-diversity.png', dpi=400, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "# display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f1a44f-20a5-4a15-b34d-0483d7ab7d9c",
   "metadata": {},
   "source": [
    "# Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237eb367-2fdb-4e04-8b39-f925a4ac2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = Top2Vec.load('../results/top2vec/top2vec_doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef5869a-23fe-4f33-b907-fba8389f978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.get_topic_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc8c567-c312-4edc-adcf-5134f0decbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92caddb1-418f-46ee-9b69-57038bd69749",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_words = {}\n",
    "\n",
    "for i in range(trained_model.get_num_topics()):\n",
    "    word_scores = []\n",
    "    for j in range(10):\n",
    "        word_scores.append((trained_model.topic_words[i][j], trained_model.topic_word_scores[i][j]))\n",
    "    top_n_words[i] = word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd5dff-2305-443f-82f8-e3c591c992ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = []\n",
    "\n",
    "for n in range(165, 4, -5):\n",
    "    # reduce number of topics\n",
    "    topic_mapping = trained_model.hierarchical_topic_reduction(n)\n",
    "            \n",
    "    # compute coherence of the model\n",
    "    cm = CoherenceModel(topics=trained_model.topic_words_reduced, topn=10, dictionary=dictionary, texts=df_sub['lemmas_filtered'], coherence='c_v')\n",
    "    coherence = cm.get_coherence()\n",
    "    \n",
    "    # compute diversity of the model\n",
    "    diversity = topic_diversity(trained_model.topic_words_reduced, top_n=10)\n",
    "    \n",
    "    results.append((n, coherence, diversity))\n",
    "    print(n, coherence, diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274eb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultstxt = pd.read_csv('../results/top2vec/top2vec.txt')\n",
    "resultstxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbac16-572b-4afe-9ae4-d1189dbeade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set font size\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# separate the x and y values into two separate lists\n",
    "x_values = [result[0] for result in results]\n",
    "y1_values = [result[1] for result in results]\n",
    "y2_values = [result[2] for result in results]\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.set_xlabel('Number of Topics')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.plot(x_values, y1_values, label ='Coherence')\n",
    "ax1.plot(x_values, y2_values, label ='Diversity')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.invert_xaxis()\n",
    "\n",
    "ax1.grid(axis=\"x\", which='major', color=\"black\", alpha=.1, linewidth=.5)\n",
    "ax1.grid(axis=\"y\", which='major', color=\"black\", alpha=.1, linewidth=.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('top2vec_reduction.png', dpi=400, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3678b40-12b1-41cf-8f12-419b994823df",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping = trained_model.hierarchical_topic_reduction(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d4441-b81b-4202-a386-a227a790255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping[-39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68a866-c682-4d7c-a23c-0820fdb5ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_words = {}\n",
    "\n",
    "for i in range(trained_model.get_num_topics()):\n",
    "    word_scores = []\n",
    "    for j in range(10):\n",
    "        word_scores.append((trained_model.topic_words[i][j], trained_model.topic_word_scores[i][j]))\n",
    "    top_n_words[i] = word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e2014e-2e37-45c9-a8bd-6a7af42008a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_words_reduced = {}\n",
    "\n",
    "for i in range(len(topic_mapping)):\n",
    "    word_scores = []\n",
    "    for j in range(10):\n",
    "        word_scores.append((trained_model.topic_words_reduced[i][j], trained_model.topic_word_scores_reduced[i][j]))\n",
    "    top_n_words_reduced[i] = word_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d2b16-e665-4a4b-b1d7-d4937995a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_words_reduced[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5a496-8817-460e-b815-791a96478e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(top_n_words, topic):\n",
    "    word_dict = {word: prob for word, prob in top_n_words[topic]}\n",
    "\n",
    "    wc = WordCloud(background_color='white', width=800, height=400)\n",
    "    wc.generate_from_frequencies(word_dict)\n",
    "\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf28bf5-cb6d-43d4-8a41-3ee3c785660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping = trained_model.hierarchical_topic_reduction(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060327a-535b-4937-860e-460594e29f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ef04e-551f-44d3-bc70-ebe8998efe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud(top_n_words, 132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0143c0e-72db-4830-9368-d70938f6a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud(top_n_words, 149)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489895e9-a494-41c2-a0a5-adf7fc06f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud(top_n_words_reduced, 111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b93c46-e1c4-4379-92f9-65f19737b12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud_save(top_n_words, name):\n",
    "    word_dict = {word: prob for word, prob in top_n_words}\n",
    "\n",
    "    wc = WordCloud(background_color='white', width=800, height=400)\n",
    "    wc.generate_from_frequencies(word_dict)\n",
    "\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(name, bbox_inches='tight', pad_inches=0, dpi=400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e3d89-4b62-456c-8ab2-d4574aeb83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud_save(top_n_words[132], 'top2vec_132.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f07a64-570d-4a78-bbb8-e0e3f3b24943",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud_save(top_n_words[149], 'top2vec_149.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba877dc-b2e0-4f88-8fff-1402ebe82e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud_save(top_n_words_reduced[111], 'top2vec_reduced_111.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7bb9eb-36b7-4068-bd4c-855e36496676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0ba90-781b-4037-959a-5e6e8c305876",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top_n_words_reduced:\n",
    "    print(i+1)\n",
    "    word_cloud(top_n_words_reduced, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e499f-b1f0-42d2-b247-3408568c9c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in top_n_words_reduced:\n",
    "    print(i+1)\n",
    "    word_cloud_save(top_n_words_reduced[i], 'top2vec_35_topics_{}.png'.format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc815c87-069e-4384-b399-8cb4dc2b6e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37fbb1-6c2c-45df-ad65-180a5fe0ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categories = ['', 'Unsupervised', 'Unsupervised', 'Unsupervised', 'Unsupervised', 'Unsupervised', 'Supervised', 'Semi--Supervised']\n",
    "methods = ['Annotated data', 'LDA (unigrams)', 'LDA (bigrams)', 'Top2Vec', 'Top2Vec (reduced)', 'K--means', 'SVM', 'c--TF--IDF']\n",
    "num_topics = [25, 40, 30, 168, 35, 55, 25, 25]\n",
    "coherences = [0.4241, 0.4513, 0.4512, 0.5614, 0.6169, 0.5397, 0.4510, 0.4716]\n",
    "diversities = [0.7440, 0.5275, 0.5500, 0.8375, 0.9600, 0.6345, 0.6400, 0.8520]\n",
    "\n",
    "idx = [categories, methods]\n",
    "\n",
    "# Calling DataFrame constructor after zipping\n",
    "# both lists, with columns specified\n",
    "df = pd.DataFrame(list(zip(num_topics, coherences, diversities)),\n",
    "               columns =['Number of topics', 'Coherence', 'Diversity'],\n",
    "                 index=idx)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fada939-025c-47da-a893-a78c6e59dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.to_latex(formatters={\"name\": str.upper},\n",
    "            float_format=\"{:.4f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a99bf76-f84e-4b4e-b8ec-5ca16aa8b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categories = ['Unsupervised', 'Unsupervised', 'Unsupervised', 'Unsupervised', 'Unsupervised', 'Supervised', 'Semi--Supervised']\n",
    "methods = ['LDA (unigrams)', 'LDA (bigrams)', 'Top2Vec', 'Top2Vec (reduced)', 'K--means', 'SVM', 'c--TF--IDF']\n",
    "topic_names = ['-', \n",
    "               '-', \n",
    "               '-', \n",
    "               '-', \n",
    "               '-', \n",
    "               'Exotics/Travel', \n",
    "               'Exotics/Travel']\n",
    "words = ['moře, vlna, loď, břeh, voda, plout, bouře, mořský, skála, veslo', \n",
    "         'moře, vlna, břeh, loď, voda, hvězda, hora, slunce, zlatý, plout', \n",
    "         'loď, plavec, plachta, přístav, koráb, člun, příď, paluba, stožár, stěžeň', \n",
    "         'loď, plavec, člun, plachta, přístav, koráb, příď, plout, stožár, vlna', \n",
    "         'člověk, rád, nebe, vědět, svět, čas, píseň, život, rok, bůh', \n",
    "         'moře, loď, vlna, břeh, plout, voda, vlak, loďka, noc, dálka', \n",
    "         'loď, vlna, moře, břeh, plout, koráb, dálka, noc, vlak, loďka']\n",
    "\n",
    "\n",
    "idx = [categories, methods]\n",
    "\n",
    "# Calling DataFrame constructor after zipping\n",
    "# both lists, with columns specified\n",
    "df1 = pd.DataFrame(list(zip(topic_names, words)),\n",
    "               columns =['Topic name', 'Top 10 words of the topic'],\n",
    "                 index=idx)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0676ae-73ca-4d77-9ef8-ed8df224a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.to_latex(formatters={\"name\": str.upper}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669df62-4ede-498b-8012-def5235032ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df1['Top 10 words of the topic']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f44fd05-e67d-4b3c-95d9-06d869eb6842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
